#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Generate a write plan for `upgradewiki.py --write`.

Goal:
- Upgrade `helloagents/` to the latest KB structure (INDEX.md/context.md/modules/archive)
- Preserve ALL existing information (no deletes)

This script only generates a JSON plan. File IO is executed by `upgradewiki.py`.

Usage:
  python -X utf8 generate_upgrade_plan.py --out plan.json [--path <project-root>]
"""

from __future__ import annotations

import argparse
import json
import re
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# Reuse HelloAGENTS helper utilities (path resolution + templates dir)
from utils import (
    get_workspace_path,
    get_plan_path,
    get_archive_path,
    get_year_month,
    get_template_loader,
    validate_base_path,
)


@dataclass(frozen=True)
class HistoryEntry:
    timestamp: str
    feature: str
    kind: str
    status: str
    rel_path: str  # e.g. helloagents/history/2026-01/202601090851_xxx/


def _read_text_or_empty(path: Path) -> str:
    if not path.exists() or not path.is_file():
        return ""
    return path.read_text(encoding="utf-8")


def _finalize_doc(md: str) -> str:
    """Normalize placeholder tokens so the upgraded KB contains no template residue."""
    # Normalize template placeholders to a stable literal.
    # User asked to "fill all"; when info is unknown, we use "æ— " rather than leaving placeholders.
    md = md.replace("(å¾…è¡¥å……)", "æ— ")
    md = re.sub(r"\{[^}]+\}", "æ— ", md)

    # Avoid repeating excessive spaces.
    md = re.sub(r"[ \t]+$", "", md, flags=re.MULTILINE)

    if not md.endswith("\n"):
        md += "\n"
    return md


def _strip_first_heading(md: str) -> str:
    # Remove the first H1 heading line to embed in other docs.
    lines = md.splitlines()
    if lines and lines[0].lstrip().startswith("#"):
        # Drop the first heading line and following blank line if present.
        lines = lines[1:]
        if lines and not lines[0].strip():
            lines = lines[1:]
    return "\n".join(lines).strip() + ("\n" if md.endswith("\n") else "")


def _normalize_tasks_statuses(md: str) -> str:
    # Convert common GitHub checkbox variants to HelloAGENTS validator-friendly ones.
    # - [x] => - [âˆš]
    # - [X] => - [X]
    md = re.sub(r"\[(x)\]", "[âˆš]", md)
    md = re.sub(r"\[( )\]", "[ ]", md)
    return md


def _parse_history_index(history_index_md: str) -> List[HistoryEntry]:
    # Expected table header in Chinese; be lenient and parse any markdown table rows.
    entries: List[HistoryEntry] = []
    lines = history_index_md.splitlines()

    in_table = False
    for line in lines:
        if line.strip().startswith("|"):
            # Detect separator row
            if re.match(r"^\|\s*-{2,}", line.strip()):
                in_table = True
                continue
            if not in_table:
                continue

            cols = [c.strip() for c in line.strip().strip("|").split("|")]
            if len(cols) < 5:
                continue

            timestamp = cols[0]
            feature = cols[1]
            kind = cols[2]
            status = cols[3]
            path_cell = cols[4]

            # Extract path inside backticks
            m = re.search(r"`([^`]+)`", path_cell)
            rel_path = m.group(1) if m else path_cell.strip()
            rel_path = rel_path.strip().rstrip("/")

            if not re.fullmatch(r"\d{12}", timestamp):
                continue
            if not feature:
                continue

            entries.append(
                HistoryEntry(
                    timestamp=timestamp,
                    feature=feature,
                    kind=kind or "æœªçŸ¥",
                    status=status or "æœªçŸ¥",
                    rel_path=rel_path,
                )
            )

    return entries


def _guess_pkg_type(kind: str) -> str:
    # Keep it simple: docs-only entries are overview; most are implementation.
    if "æ–‡æ¡£" in kind:
        return "overview"
    return "implementation"


def _infer_modules_for_entry(feature: str, kind: str) -> str:
    """Infer affected modules for archive index based on feature naming."""
    f = (feature or "").lower()

    # Specific keywords
    if "networkplayer" in f:
        return "networkplayer"
    if "trade" in f or "tradepanel" in f:
        return "networkplugin"
    if "resurrect" in f:
        return "networkplugin"
    if "event" in f or "dialog" in f:
        return "networkplugin"
    if "turn" in f:
        return "networkplugin"
    if "midgame" in f or "join" in f:
        return "networkplugin"
    if "networkmanager" in f:
        return "networkplugin"
    if "nat" in f or "upnp" in f or "stun" in f:
        return "networkplugin"
    if "server" in f or "relay" in f:
        return "networkplugin"
    if "carduse" in f or "remote" in f:
        return "networkplugin"

    # Kind hints
    if "æ–‡æ¡£" in kind:
        return "(docs)"

    return "networkplugin"


def _render_index(project_name: str, last_updated: str, module_count: int, pending_plans: int) -> str:
    loader = get_template_loader()
    tmpl = loader.load("INDEX.md") or "# {project_name} çŸ¥è¯†åº“\n"
    content = tmpl
    content = content.replace("{project_name}", project_name)

    # Fill YAML block placeholders (best-effort)
    content = content.replace("{YYYY-MM-DD HH:MM}", last_updated)
    content = content.replace("{æ•°é‡}", str(module_count), 1)  # modules
    content = content.replace("{æ•°é‡}", str(pending_plans), 1)  # plans

    # Avoid leaving raw placeholders when replacement count mismatches.
    content = re.sub(r"\{YYYY-MM-DD HH:MM\}", last_updated, content)

    # Avoid dead placeholder links: keep the example as inline code.
    content = content.replace("[modules/{æ¨¡å—å}.md](modules/{æ¨¡å—å}.md)", "`modules/<æ¨¡å—å>.md`")
    content = content.replace("modules/{æ¨¡å—å}.md", "modules/<æ¨¡å—å>.md")

    # Keep generic archive/plan guidance without being normalized into "æ— ".
    content = content.replace("archive/{YYYY-MM}/{æ–¹æ¡ˆåŒ…}/proposal.md", "archive/<YYYY-MM>/<æ–¹æ¡ˆåŒ…>/proposal.md")
    content = content.replace("plan/{æ–¹æ¡ˆåŒ…}/*", "plan/<æ–¹æ¡ˆåŒ…>/*")

    return _finalize_doc(content)


def _render_context(project_name: str, overview: str, arch: str, tech: str) -> str:
    loader = get_template_loader()
    tmpl = loader.load("context.md") or "# é¡¹ç›®ä¸Šä¸‹æ–‡\n"

    # Fill with real data where we can.
    content = tmpl
    content = content.replace("{é¡¹ç›®åç§°}", project_name)
    content = content.replace("{ä¸€å¥è¯æè¿°}", "LBoL è”æœº/åŒæ­¥ Modï¼ˆHarmony Patch + LiteNetLibï¼‰")
    content = content.replace("{Webåº”ç”¨/CLIå·¥å…·/åº“/æœåŠ¡/...}", "LBoL Mod")
    content = content.replace("{å¼€å‘ä¸­/ç»´æŠ¤ä¸­/ç¨³å®š}", "å¼€å‘ä¸­")

    content = content.replace("{ä¸»è¦ç¼–ç¨‹è¯­è¨€}", "C#")
    content = content.replace("{ä½¿ç”¨çš„æ¡†æ¶}", "Harmony + LiteNetLib")
    content = content.replace("{npm/pip/cargo/...}", ".NET SDK")
    content = content.replace("{webpack/vite/gradle/...}", "dotnet build")

    # Minimal dependencies row - keep placeholders removed.
    content = content.replace("| {ä¾èµ–å} | {ç‰ˆæœ¬} | {ç”¨é€”è¯´æ˜} |", "| Harmony | (repo) | Patch æ¡†æ¶ |\n| LiteNetLib | (repo) | ç½‘ç»œä¼ è¾“ |")

    # Core functionality and boundaries.
    content = content.replace("- {åŠŸèƒ½1}", "- è”æœºåŒæ­¥ï¼šç½‘ç»œæ¶ˆæ¯/äº‹ä»¶é€šé“ï¼ˆGameEventï¼‰")
    content = content.replace("- {åŠŸèƒ½2}", "- Harmony è¡¥ä¸ï¼šæˆ˜æ–—/äº‹ä»¶/äº¤æ˜“ç­‰å…³é”®äº¤äº’åŒæ­¥")

    content = content.replace("- {åšä»€ä¹ˆ}", "- è®© LBoL æ”¯æŒå¤šäººè”æœºå¹¶åŒæ­¥å…³é”®çŠ¶æ€")
    content = content.replace("- {ä¸åšä»€ä¹ˆ}", "- ä¸æ‰¿è¯ºå…¼å®¹æ‰€æœ‰ç¬¬ä¸‰æ–¹ Modï¼›ä¸åšäº‘å­˜æ¡£/è´¦å·ä½“ç³»")

    # Conventions: reuse existing project.md snippets.
    content = content.replace("{é©¼å³°/ä¸‹åˆ’çº¿/...}", "ä¸ç°æœ‰ä»£ç ä¸€è‡´")
    content = content.replace("{è§„åˆ™}", "ä¸ç°æœ‰ç›®å½•ç»“æ„ä¸€è‡´")

    content = content.replace("{æ ¼å¼è¯´æ˜}", "ä»¥æ—¥å¿—ä¸ºä¸»ï¼ˆå¿…è¦æ—¶ JSON ç»“æ„ï¼‰")
    content = content.replace("{çº§åˆ«è¯´æ˜}", "Info/Warn/Error")

    content = content.replace("{æ¡†æ¶å}", "(æœªç»Ÿä¸€)ï¼›å¯ç”¨æ„å»ºéªŒè¯ä»£æ›¿")
    content = content.replace("{ç™¾åˆ†æ¯”}", "(æœªè®¾å®š)")
    content = content.replace("{è·¯å¾„}", "(æ— å›ºå®šè·¯å¾„)")

    content = content.replace("{ç­–ç•¥}", "(æœªçº¦æŸ)")
    content = content.replace("{æ ¼å¼}", "(æœªçº¦æŸ)")

    # Constraints: include ADR pointers derived from arch.md.
    constraints_table = (
        "| çº¦æŸ | åŸå›  | å†³ç­–æ¥æº |\n"
        "|------|------|----------|\n"
        "| è¿œç«¯é˜Ÿå‹ç›®æ ‡å‡ºç‰Œï¼šç›®æ ‡ç«¯ç»“ç®— + å¿«ç…§å¹¿æ’­ | åŠ¨ç”»ä¸€è‡´ä¸”é¿å…é‡å¤ç»“ç®— | archive/2026-01/202601090851_remote_target_card/proposal.md#D001 |\n"
        "| ServerCore åŒæ¨¡å¼ï¼ˆHost/Relayï¼‰ | å¤ç”¨æ ¸å¿ƒå¹¶ç»Ÿä¸€æ¶ˆæ¯é“¾è·¯ | archive/2026-01/202601091556_unify_server_core_two_modes/proposal.md#D001 |\n"
    )
    content = re.sub(r"\| \{çº¦æŸæè¿°\} \| \{ç®€è¦åŸå› \} \| \[\{æ–¹æ¡ˆåŒ…å\}#D\{NNN\}\].*?\|", constraints_table, content)

    # Fill technical debt table with concrete items.
    debt_table = (
        "| å€ºåŠ¡æè¿° | ä¼˜å…ˆçº§ | æ¥æº | å»ºè®®å¤„ç†æ—¶æœº |\n"
        "|---------|--------|------|-------------|\n"
        "| ç¼ºå°‘è‡ªåŠ¨åŒ–è”æœº/åŒæ­¥å›å½’æµ‹è¯•ï¼ˆä¸»è¦ä¾èµ–æ‰‹åŠ¨è”æœºéªŒè¯ï¼‰ | P1 | é¡¹ç›®çº¦å®š | ä¿®æ”¹ç½‘ç»œ/è¡¥ä¸é€»è¾‘åç«‹å³æ‰§è¡Œ |\n"
        "| æ–‡æ¡£ä¸ä»£ç ä¸€è‡´æ€§éœ€æŒç»­ç»´æŠ¤ï¼ˆæ–°å¢äº‹ä»¶/è½½è·æ—¶éœ€åŒæ­¥ modules/protocol.mdï¼‰ | P2 | çŸ¥è¯†åº“å‡çº§ | æ¯æ¬¡æ–°å¢æ¶ˆæ¯ç±»å‹æ—¶ |\n"
    )
    content = re.sub(
        r"\| å€ºåŠ¡æè¿° \| ä¼˜å…ˆçº§ \| æ¥æº \| å»ºè®®å¤„ç†æ—¶æœº \|[\s\S]*?\| \(å¾…è¡¥å……\) \| P0/P1/P2 \| \(å¾…è¡¥å……\) \| \(å¾…è¡¥å……\) \|",
        debt_table,
        content,
        flags=re.MULTILINE,
    )

    # Append a short appendix with migrated raw docs (so nothing is lost).
    appendix_parts: List[str] = []
    if tech.strip():
        appendix_parts.append("## é™„å½•Aï¼šæ—§ç‰ˆ project.mdï¼ˆåŸæ–‡ä¿ç•™ï¼‰\n\n" + tech.strip() + "\n")
    if overview.strip():
        appendix_parts.append("## é™„å½•Bï¼šæ—§ç‰ˆ wiki/overview.mdï¼ˆåŸæ–‡ä¿ç•™ï¼‰\n\n" + overview.strip() + "\n")
    if arch.strip():
        appendix_parts.append("## é™„å½•Cï¼šæ—§ç‰ˆ wiki/arch.mdï¼ˆåŸæ–‡ä¿ç•™ï¼‰\n\n" + arch.strip() + "\n")

    if appendix_parts:
        content = content.rstrip() + "\n\n---\n\n" + "\n\n".join(appendix_parts)

    return _finalize_doc(content)


def _render_modules_index() -> str:
    loader = get_template_loader()
    tmpl = loader.load("modules/_index.md") or "# æ¨¡å—ç´¢å¼•\n"

    rows = [
        "| æ¨¡å— | èŒè´£ | çŠ¶æ€ | æ–‡æ¡£ |",
        "|------|------|------|------|",
        "| networkplugin | è”æœºåŒæ­¥ä¸ UI/è¡¥ä¸ä¸»æ¨¡å— | ğŸš§ | [networkplugin.md](./networkplugin.md) |",
        "| networkplayer | ç©å®¶æ¨¡å‹/DTO/å…¼å®¹å±‚ | âœ… | [networkplayer.md](./networkplayer.md) |",
        "| protocol | ç½‘ç»œäº‹ä»¶/è½½è·/æ•°æ®æ¨¡å‹ | âœ… | [protocol.md](./protocol.md) |",
    ]

    dep = (
        "networkplugin â†’ protocol\n"
        "networkplugin â†’ networkplayer\n"
        "networkplayer â†’ protocol\n"
    )

    content = tmpl
    content = re.sub(r"\| \{æ¨¡å—å\} \| \{ä¸€å¥è¯èŒè´£\} \| âœ…/ğŸš§/ğŸ“ \| \[\{æ¨¡å—å\}\.md\].*?\|", "\n".join(rows), content)
    content = content.replace("æ¨¡å—A â†’ æ¨¡å—B â†’ æ¨¡å—C\n      â†˜ æ¨¡å—D", dep)
    return _finalize_doc(content)


def _render_module_doc(module_name: str, purpose: str, raw_md: str, deps: List[str], rdeps: List[str]) -> str:
    """Render a module doc using the module template but with all fields filled."""
    loader = get_template_loader()
    tmpl = loader.load("modules/module.md") or "# {æ¨¡å—å}\n\n## èŒè´£\n\n{è¯¦ç»†èŒè´£æè¿°}\n"

    content = tmpl.replace("{æ¨¡å—å}", module_name)

    preserved = raw_md.strip() or "(æ— )"

    # èŒè´£
    content = content.replace(
        "{è¯¦ç»†èŒè´£æè¿°}",
        purpose.strip() + "\n\n---\n\nä»¥ä¸‹å†…å®¹ä»æ—§ç‰ˆ wiki è¿ç§»ï¼Œä¿æŒåŸæ–‡ï¼š\n\n" + preserved,
    )

    # Interface: keep minimal but concrete.
    content = content.replace(
        "| {åç§°} | {å‚æ•°åˆ—è¡¨} | {è¿”å›ç±»å‹} | {åŠŸèƒ½è¯´æ˜} |",
        "| (è§æ–‡æ¡£åŸæ–‡) | - | - | æ¨¡å—æ¥å£ä»¥ä»£ç ä¸ºå‡†ï¼Œæ–‡æ¡£è®°å½•å…³é”®çº¦å®š |",
    )
    content = content.replace(
        "| {å­—æ®µå} | {ç±»å‹} | {ç”¨é€”è¯´æ˜} |",
        "| - | - | - |",
    )

    # Behavior section: keep one scenario pointing readers to the migrated content.
    content = content.replace("{åœºæ™¯åç§°}", "æ ¸å¿ƒåœºæ™¯")
    content = content.replace("{å‰ç½®æ¡ä»¶}", "éœ€è¦è”æœºè¿æ¥ï¼ˆHost/Relayï¼‰")
    content = content.replace("{é¢„æœŸè¡Œä¸º}", "æŒ‰æ¨¡å—çº¦å®šå‘é€/æ¥æ”¶äº‹ä»¶å¹¶ä¿è¯ä¸€è‡´æ€§")
    content = content.replace("{é¢„æœŸç»“æœ}", "æœ¬åœ°ä¸è¿œç«¯çŠ¶æ€æ”¶æ•›ä¸€è‡´")

    dep_str = ", ".join(deps) if deps else "æ— "
    rdep_str = ", ".join(rdeps) if rdeps else "æ— "
    content = content.replace("ä¾èµ–: {ä¾èµ–æ¨¡å—åˆ—è¡¨}", f"ä¾èµ–: {dep_str}")
    content = content.replace("è¢«ä¾èµ–: {è¢«ä¾èµ–æ¨¡å—åˆ—è¡¨}", f"è¢«ä¾èµ–: {rdep_str}")

    return _finalize_doc(content)


def _render_protocol(api_md: str, data_md: str) -> str:
    merged = []
    if api_md.strip():
        merged.append("## æ¥æºï¼šwiki/api.md\n\n" + _strip_first_heading(api_md).strip())
    if data_md.strip():
        merged.append("## æ¥æºï¼šwiki/data.md\n\n" + _strip_first_heading(data_md).strip())
    body = "\n\n".join([m for m in merged if m.strip()])
    return _render_module_doc(
        module_name="protocol",
        purpose="å®šä¹‰ç½‘ç»œäº‹ä»¶/è½½è·/æ•°æ®æ¨¡å‹çš„æ–‡æ¡£çº¦å®šï¼ˆä»¥ä»£ç å®ç°ä¸ºå‡†ï¼‰ã€‚",
        raw_md=body,
        deps=[],
        rdeps=["networkplugin", "networkplayer"],
    )


def _render_archive_index(entries: List[HistoryEntry]) -> str:
    loader = get_template_loader()
    tmpl = loader.load("archive/_index.md") or "# æ–¹æ¡ˆå½’æ¡£ç´¢å¼•\n"

    # Build a simple current-year table.
    rows = [
        "| æ—¶é—´æˆ³ | åç§° | ç±»å‹ | æ¶‰åŠæ¨¡å— | å†³ç­– | ç»“æœ |",
        "|--------|------|------|---------|------|------|",
    ]

    for e in entries:
        affected = _infer_modules_for_entry(e.feature, e.kind)
        rows.append(f"| {e.timestamp} | {e.feature} | {e.kind} | {affected} | {e.feature}#D001 | {e.status} |")

    content = tmpl
    content = re.sub(r"\| \{YYYYMMDDHHMM\} \| \{feature\} .*?\|", "\n".join(rows), content)

    # Build monthly bullet list.
    by_month: Dict[str, List[HistoryEntry]] = {}
    for e in entries:
        by_month.setdefault(get_year_month(e.timestamp), []).append(e)

    month_blocks: List[str] = []
    for month in sorted(by_month.keys(), reverse=True):
        items = by_month[month]
        items.sort(key=lambda x: x.timestamp)
        lines = [f"### {month}"]
        for e in items:
            pkg = f"{e.timestamp}_{e.feature}"
            lines.append(f"- [{pkg}](./{month}/{pkg}/) - {e.kind} / {e.status}")
        month_blocks.append("\n".join(lines))

    # Replace the example YYYY-MM section.
    content = re.sub(r"### YYYY-MM[\s\S]*?$", "\n\n".join(month_blocks) + "\n", content, flags=re.MULTILINE)

    # Replace year links hint to avoid dead links.
    content = content.replace("> å†å²å¹´ä»½: [2024](_index-2024.md) | [2023](_index-2023.md) | ...", "> å†å²å¹´ä»½: 2026ï¼ˆå½“å‰ï¼‰")

    # Remove the template example bullet if it still exists.
    content = re.sub(r"\n- \[YYYYMMDDHHMM_feature\]\(\./YYYY-MM/.*?\) - .*?\n", "\n", content)

    return _finalize_doc(content)


def _render_archive_package_proposal(entry: HistoryEntry, why_md: str, how_md: str) -> str:
    loader = get_template_loader()
    tmpl = loader.load("plan/proposal.md") or "# å˜æ›´ææ¡ˆ: {feature}\n"

    date = f"{entry.timestamp[:4]}-{entry.timestamp[4:6]}-{entry.timestamp[6:8]}"
    pkg_type = _guess_pkg_type(entry.kind)

    repl = {
        "{feature}": entry.feature,
        "{YYYY-MM-DD}": date,
        "{pkg_type}": pkg_type,
    }

    content = tmpl
    for k, v in repl.items():
        content = content.replace(k, v)

    # Fill meta fields that are not placeholders
    content = content.replace("ç±»å‹: æ–°åŠŸèƒ½/ä¿®å¤/é‡æ„/ä¼˜åŒ–", f"ç±»å‹: {entry.kind}")
    content = content.replace("ä¼˜å…ˆçº§: P0/P1/P2/P3", "ä¼˜å…ˆçº§: P2")
    content = content.replace("çŠ¶æ€: è‰ç¨¿", f"çŠ¶æ€: å½’æ¡£({entry.status})")

    affected = _infer_modules_for_entry(entry.feature, entry.kind)

    # Inject migrated content into key sections.
    why_body = _strip_first_heading(why_md).strip()
    how_body = _strip_first_heading(how_md).strip()

    if not why_body:
        why_body = "(æ— )"
    if not how_body:
        how_body = "(æ— )"

    content = content.replace("{ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªå˜æ›´}", why_body)
    content = content.replace("{è¦è¾¾æˆä»€ä¹ˆç›®æ ‡}", f"å®Œæˆ {entry.feature} çš„æ–¹æ¡ˆå½’æ¡£ï¼Œå¹¶ä¿è¯èµ„æ–™åœ¨æ–°ç‰ˆçŸ¥è¯†åº“ç»“æ„ä¸­å¯è¿½æº¯ã€‚")

    content = content.replace("{ç®€è¦æè¿°å®ç°æ–¹å¼}", how_body)

    # Impact scope
    content = content.replace("- {æ¨¡å—1}: {å½±å“è¯´æ˜}", f"- {affected}: æ–¹æ¡ˆ/å®ç°/æ–‡æ¡£æ›´æ–°")
    content = content.replace("é¢„è®¡å˜æ›´æ–‡ä»¶: {æ•°é‡}", "é¢„è®¡å˜æ›´æ–‡ä»¶: å·²å®Œæˆï¼ˆå½’æ¡£ï¼‰")

    # Risks
    content = content.replace("| {é£é™©} | é«˜/ä¸­/ä½ | {æªæ–½} |", "| èµ„æ–™è¿ç§»é—æ¼ | ä½ | åŸå§‹æ–‡ä»¶ä¿ç•™ + ç”Ÿæˆæ–°ç‰ˆå½’æ¡£ |")

    # Decision section
    content = content.replace("{å†³ç­–æ ‡é¢˜}", "é‡‡ç”¨ç°æœ‰æ–¹æ¡ˆå¹¶æŒ‰æ–°ç‰ˆæ¨¡æ¿å½’æ¡£")
    content = content.replace("{ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªå†³ç­–}", "éœ€è¦å°†å†å²æ–¹æ¡ˆè¿ç§»åˆ°ç»Ÿä¸€ç»“æ„ï¼Œä¾¿äºæ£€ç´¢ä¸åç»­ç»´æŠ¤ã€‚")
    content = content.replace("A: {æ–¹æ¡ˆA}", "A: ç›´æ¥å½’æ¡£ï¼ˆæ¨èï¼‰")
    content = content.replace("B: {æ–¹æ¡ˆB}", "B: é‡å†™æ–¹æ¡ˆåå½’æ¡£")
    content = content.replace("{ä¼˜ç‚¹}", "æˆæœ¬ä½")
    content = content.replace("{ç¼ºç‚¹}", "å¯èƒ½ä¿ç•™å†å²è¡¨è¿°é£æ ¼")
    content = content.replace("{è¯¦ç»†ç†ç”±}", "ä¿ç•™åŸæ–‡ä»¥é¿å…ä¿¡æ¯ä¸¢å¤±ï¼ŒåŒæ—¶è¡¥é½ç´¢å¼•ä¸ç»“æ„ã€‚")
    content = content.replace("{å¯¹å“ªäº›æ¨¡å—æœ‰å½±å“}", affected)

    # Make acceptance reflect archived status.
    content = content.replace("- [ ] {æ ‡å‡†1}", "- [âˆš] èµ„æ–™å·²è¿ç§»å¹¶å¯è¿½æº¯")
    content = content.replace("- [ ] {æ ‡å‡†2}", "- [âˆš] å½’æ¡£åŒ…åŒ…å« proposal.md + tasks.md")

    return _finalize_doc(content)


def _render_archive_package_tasks(entry: HistoryEntry, task_md: str) -> str:
    loader = get_template_loader()
    tmpl = loader.load("plan/tasks.md") or "# ä»»åŠ¡æ¸…å•: {feature}\n"

    date = f"{entry.timestamp[:4]}-{entry.timestamp[4:6]}-{entry.timestamp[6:8]}"
    pkg_name = f"{entry.timestamp}_{entry.feature}"

    content = tmpl
    content = content.replace("{feature}", entry.feature)
    content = content.replace("helloagents/plan/{YYYYMMDDHHMM}_{feature}/", f"helloagents/archive/{get_year_month(entry.timestamp)}/{pkg_name}/")

    # Inject the original tasks list below "ä»»åŠ¡åˆ—è¡¨" to preserve details.
    task_body = _strip_first_heading(_normalize_tasks_statuses(task_md)).strip()
    if not task_body:
        task_body = "(æ— ä»»åŠ¡æ˜ç»†)"

    # Replace the placeholder tasks list block.
    # Use a function replacement so backslashes in markdown are not treated as regex escapes.
    replacement = "## ä»»åŠ¡åˆ—è¡¨\n\n" + task_body + "\n\n---\n\n## æ‰§è¡Œå¤‡æ³¨"
    content = re.sub(
        r"## ä»»åŠ¡åˆ—è¡¨[\s\S]*?## æ‰§è¡Œå¤‡æ³¨",
        lambda _m: replacement,
        content,
        flags=re.MULTILINE,
    )

    # Update execution status header quickly (archived):
    content = re.sub(r"æ€»ä»»åŠ¡: X", "æ€»ä»»åŠ¡: (å·²å½’æ¡£)", content)
    content = re.sub(r"å·²å®Œæˆ: 0", f"å·²å®Œæˆ: (å‚è€ƒåŸä»»åŠ¡åˆ—è¡¨)", content)
    content = re.sub(r"å®Œæˆç‡: 0%", "å®Œæˆç‡: (å‚è€ƒåŸä»»åŠ¡åˆ—è¡¨)", content)

    if not content.endswith("\n"):
        content += "\n"

    return _finalize_doc(content)


def generate_plan(project_root: Path) -> Dict:
    kb_root = get_workspace_path(str(project_root))

    # Source docs
    overview = _read_text_or_empty(kb_root / "wiki" / "overview.md")
    api_md = _read_text_or_empty(kb_root / "wiki" / "api.md")
    arch_md = _read_text_or_empty(kb_root / "wiki" / "arch.md")
    data_md = _read_text_or_empty(kb_root / "wiki" / "data.md")

    wiki_networkplugin = _read_text_or_empty(kb_root / "wiki" / "modules" / "networkplugin.md")
    wiki_networkplayer = _read_text_or_empty(kb_root / "wiki" / "modules" / "networkplayer.md")

    project_md = _read_text_or_empty(kb_root / "project.md")
    history_index_md = _read_text_or_empty(kb_root / "history" / "index.md")

    entries = _parse_history_index(history_index_md)

    # Compute counts
    project_name = project_root.name
    last_updated = "2026-01-22 00:00"

    pending_plans = 0
    plan_dir = get_plan_path(str(project_root))
    if plan_dir.exists() and plan_dir.is_dir():
        for child in plan_dir.iterdir():
            if child.is_dir() and not child.name.startswith("."):
                pending_plans += 1

    module_count = 3

    operations: List[Dict] = []

    # Ensure top-level directories exist.
    operations.append({"action": "mkdir", "path": "modules"})
    operations.append({"action": "mkdir", "path": "archive"})

    # Root files
    operations.append({
        "action": "write",
        "path": "INDEX.md",
        "content": _render_index(project_name, last_updated, module_count, pending_plans),
    })
    operations.append({
        "action": "write",
        "path": "context.md",
        "content": _render_context(project_name, overview, arch_md, project_md),
    })

    # Modules
    operations.append({
        "action": "write",
        "path": "modules/_index.md",
        "content": _render_modules_index(),
    })

    operations.append({
        "action": "write",
        "path": "modules/networkplugin.md",
        "content": _render_module_doc(
            module_name="networkplugin",
            purpose="æä¾›è”æœºåŒæ­¥ä¸ UI æ‰©å±•è¡¥ä¸ï¼ˆHarmonyPatch + LiteNetLibï¼‰ã€‚",
            raw_md=wiki_networkplugin,
            deps=["protocol", "networkplayer"],
            rdeps=[],
        ),
    })
    operations.append({
        "action": "write",
        "path": "modules/networkplayer.md",
        "content": _render_module_doc(
            module_name="networkplayer",
            purpose="å®šä¹‰çŸ¥è¯†åº“å±‚é¢çš„ NetworkPlayer åˆ†å±‚çº¦å®šä¸å…¼å®¹å±‚è¯´æ˜ï¼ˆDTO/è¿è¡Œæ—¶æ¨¡å‹ï¼‰ã€‚",
            raw_md=wiki_networkplayer,
            deps=["protocol"],
            rdeps=["networkplugin"],
        ),
    })
    operations.append({
        "action": "write",
        "path": "modules/protocol.md",
        "content": _render_protocol(api_md, data_md),
    })

    # Archive index
    operations.append({
        "action": "write",
        "path": "archive/_index.md",
        "content": _render_archive_index(entries),
    })

    # Archive packages
    for e in entries:
        ym = get_year_month(e.timestamp)
        pkg = f"{e.timestamp}_{e.feature}"
        base = f"archive/{ym}/{pkg}"
        operations.append({"action": "mkdir", "path": f"archive/{ym}"})
        operations.append({"action": "mkdir", "path": base})

        pkg_dir = project_root / e.rel_path
        why_md = _read_text_or_empty(pkg_dir / "why.md")
        how_md = _read_text_or_empty(pkg_dir / "how.md")
        task_md = _read_text_or_empty(pkg_dir / "task.md")

        operations.append({
            "action": "write",
            "path": f"{base}/proposal.md",
            "content": _render_archive_package_proposal(e, why_md, how_md),
        })
        operations.append({
            "action": "write",
            "path": f"{base}/tasks.md",
            "content": _render_archive_package_tasks(e, task_md),
        })

    return {"operations": operations}


def main() -> None:
    parser = argparse.ArgumentParser(description="Generate HelloAGENTS KB upgrade write plan")
    parser.add_argument("--out", required=True, help="Output plan JSON file")
    parser.add_argument("--path", default=None, help="Project root (default: cwd)")
    args = parser.parse_args()

    base = validate_base_path(args.path)
    plan = generate_plan(base)

    out_path = Path(args.out)
    out_path.write_text(json.dumps(plan, ensure_ascii=False, indent=2), encoding="utf-8")

    print(json.dumps({
        "ok": True,
        "out": str(out_path),
        "operations": len(plan.get("operations", [])),
    }, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()
